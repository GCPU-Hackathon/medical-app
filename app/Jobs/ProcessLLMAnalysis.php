<?php

namespace App\Jobs;

use App\Models\Study;
use App\Models\StudyStep;
use Illuminate\Bus\Queueable;
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Foundation\Bus\Dispatchable;
use Illuminate\Queue\InteractsWithQueue;
use Illuminate\Queue\SerializesModels;
use Illuminate\Support\Facades\Log;
use Illuminate\Support\Facades\Http;
use Illuminate\Support\Facades\Storage;

class ProcessLLMAnalysis implements ShouldQueue
{
    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;

    public $timeout = 300; // 5 minutes max for entire job
    public $tries = 1;

    /**
     * Create a new job instance.
     */
    public function __construct(public Study $study)
    {
        //
    }

    /**
     * Execute the job.
     */
    public function handle(): void
    {
        $step = StudyStep::create([
            'study_id' => $this->study->id,
            'name' => 'LLM Analysis',
            'description' => 'Generating AI-powered medical analysis and insights',
            'status' => 'in_progress',
            'step_order' => 5,
            'started_at' => now(),
        ]);

        try {
            Log::info("Starting LLM analysis for Study: {$this->study->code}");
            
            // Send request to medchatbot to start conversation with aggressive timeout
            Log::info("Sending request to medchatbot service", [
                'study_code' => $this->study->code,
                'endpoint' => 'http://medchatbot:8000/conversation/start'
            ]);
            
            $response = Http::
                withoutVerifying()
                ->timeout(80)
                ->post('https://medchatbot:8000/conversation/start', [
                    'study_id' => $this->study->id,
                    'study_code' => $this->study->code
                ]);
            
            Log::info("Received response from medchatbot service", [
                'study_code' => $this->study->code,
                'status' => $response->status(),
                'successful' => $response->successful()
            ]);
            
            if (!$response->successful()) {
                Log::error("LLM Analysis API request failed", [
                    'study_code' => $this->study->code,
                    'status' => $response->status(),
                    'body' => $response->body(),
                    'headers' => $response->headers()
                ]);
                
                throw new \Exception(
                    "LLM Analysis API failed with status {$response->status()}: " . $response->body()
                );
            }
            
            $result = $response->json();
            
            Log::info("LLM Analysis conversation started", [
                'study_code' => $this->study->code,
                'conversation_id' => $result['conversation_id'] ?? 'unknown'
            ]);
            
            // Store the generated report.pdf file
            $this->storeReportFile();
            
            // Update step as completed
            $step->update([
                'status' => 'completed',
                'completed_at' => now(),
                'notes' => "LLM Analysis completed successfully. Conversation ID: " . ($result['conversation_id'] ?? 'unknown'),
            ]);

            Log::info("LLM Analysis completed successfully for Study: {$this->study->code}");
            
        } catch (\Exception $e) {
            Log::error("LLM analysis failed for Study: {$this->study->code}", [
                'error' => $e->getMessage(),
                'trace' => $e->getTraceAsString()
            ]);
            
            $step->update([
                'status' => 'failed',
                'completed_at' => now(),
                'notes' => 'LLM analysis failed: ' . $e->getMessage(),
            ]);

            $this->study->update([
                'status' => 'failed',
                'processing_completed_at' => now(),
                'processing_errors' => array_merge(
                    $this->study->processing_errors ?? [],
                    ['llm_analysis' => $e->getMessage()]
                )
            ]);
            
            throw $e;
        }
    }

    /**
     * Store the report file generated by LLM analysis
     */
    private function storeReportFile(): void
    {
        $localDisk = Storage::disk('local');
        $reportFilePath = "studies/{$this->study->code}/report.pdf";
        
        // Check if report.pdf exists
        if (!$localDisk->exists($reportFilePath)) {
            throw new \Exception("report.pdf not found for study {$this->study->code} - LLM analysis failed");
        }
        
        $absolutePath = $localDisk->path($reportFilePath);
        $fileSize = filesize($absolutePath);
        
        // Create new report asset
        $asset = $this->study->assets()->create([
            'filename' => 'report.pdf',
            'file_path' => $reportFilePath,
            'file_size' => $fileSize,
            'mime_type' => 'application/pdf',
            'asset_type' => 'report',
            'metadata' => [
                'created_by_llm_analysis' => true,
                'processed_at' => now()->toDateTimeString()
            ]
        ]);
        
        Log::info("Created new report asset", [
            'study_code' => $this->study->code,
            'filename' => 'report.pdf',
            'asset_id' => $asset->id,
            'path' => $reportFilePath,
            'size' => round($fileSize / 1024, 2) . ' KB'
        ]);
    }

    /**
     * Get the tags that should be assigned to the job.
     */
    public function tags(): array
    {
        return ['llm-analysis', "study:{$this->study->code}"];
    }
}
